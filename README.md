# Deep Learning for Music Generation

# Papers
## MIDI

- **Deep Learning Techniques for Music Generation - A Survey** (2017.9) [[arXiv](https://arxiv.org/abs/1709.01620)]

- **MidiNet: A Convolutional Generative Adversarial Network for Symbolic-domain Music Generation using 1D and 2D Conditions** - **ISMIR 2017** (2017.3) [[arXiv](https://arxiv.org/abs/1703.10847)] [[Page](https://richardyang40148.github.io/TheBlog/midinet_arxiv_demo.html)] [[Code](https://github.com/Chinglohsiu/MidiNet/tree/master/v1)] 

- **C-RNN-GAN: Continuous Recurrent Neural Networks with Adversarial Training** (2016.11) [[arXiv](https://arxiv.org/abs/1611.09904)] [[Code](https://github.com/olofmogren/c-rnn-gan)]

- **DeepJ: A model for style-specific music generation**  (2018.1) [[arXiv](https://arxiv.org/abs/1801.00887)] [[Page](https://deepj.ai)] [[Code-Keras](https://github.com/calclavia/DeepJ/tree/icsc)]

- **A Classifying Variational Autoencoder with Application to Polyphonic Music Generation** (2017.11) [[arXiv](https://arxiv.org/abs/1711.07050)] [[Page](https://mobeets.github.io/classifying-vae-lstm/)] [[Code-Keras](https://github.com/mobeets/classifying-vae-lstm)]

- **A hierarchical recurrent variational autoencoder for music** (2018.3) [[arXiv](https://arxiv.org/abs/1803.05428)] [[Page](https://magenta.tensorflow.org/music-vae)] [[Code-Tensorflow](https://github.com/tensorflow/magenta/tree/master/magenta/models/music_vae)]

- **Multitrack MusicVAE: Interactively Exploring Musical Styles** (2018.6) [[Page](https://magenta.tensorflow.org/multitrack)]

- **MuseGAN: Symbolic-domain Music Generation and Accompaniment with Multi-track Sequential Generative Adversarial Networks** (2017.9) [[arXiv](https://arxiv.org/abs/1709.06298)] [[Page](https://salu133445.github.io/musegan/)]

- **GLSR-VAE: Geodesic Latent Space Regularization for Variational AutoEncoder Architectures** (2017.7) [[arXiv](https://arxiv.org/abs/1707.04588)]

- **SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient** - **AAAI 2017** (2016.9) [[Paper](http://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14344/14489)] [[Code](https://github.com/LantaoYu/SeqGAN)]

- **Song From PI: A Musically Plausible Network for Pop Music Generation** - **ICLR 2017** [[arXiv](https://arxiv.org/abs/1611.03477)]

- **Modeling Temporal Dependencies in High-dimensional Sequences: Application to Polyphonic Music Generation and Transcription** (2012) [[arXiv](https://arxiv.org/abs/1206.6392)]



## Audio

# Useful models

- **A Hybrid Convolutional Variational Autoencoder for Text Generation** (2017.2) [[arXiv](https://	arXiv:1702.02390)] [[Code-Pytorch](https://github.com/kefirski/hybrid_rvae)]
 
- **Generating Sentences from a Continuous Space** (2015.11) [[arXiv](https://arxiv.org/abs/1511.06349#)] [[Code-Pytorch](https://github.com/kefirski/pytorch_RVAE)]

- **Improved Variational Autoencoders for Text Modeling using Dilated Convolutions** (2017.6) [[arXiv](https://arxiv.org/abs/1702.08139)] [[Code-Pytorch](https://github.com/kefirski/contiguous-succotash)]

# Blogs

# Projects

- **Magenta: Music and Art Generation with Machine Intelligence** [[Page](https://magenta.tensorflow.org/)][[Model](https://github.com/tensorflow/magenta/tree/master/magenta/models)]

# Applications

* [Jukedeck](https://www.jukedeck.com/?no-redirect=true)
* [Amper music](https://www.ampermusic.com/)
* AIVA
* [YouBand 迪声软件，悠悠虚拟乐队](http://www.dsoundsoft.com/)

# Confercence & Journal

- **ACM MM** - ACM MultiMedia 
- **ISMIR** - The International Society of Music Information Retrieval 
- **ICASSP** - Conference on Acoustics, Speech and Signal Processing 
- **DLM** - Deep Learning for Music Workshop 
- **CSMC** - Conference on Computer Simulation of Musical  Creativity 
- **CCRMA** - Center for Computer Research in Music and Acoustics (Stanford University) 
- **ICMC** - Internatonal Computer Music Conference

- **TAC** - IEEE Transaction on Affective Computing

